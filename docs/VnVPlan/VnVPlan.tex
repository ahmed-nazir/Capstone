\documentclass[12pt, titlepage]{article}

\usepackage{booktabs}
\usepackage{colortbl}
\usepackage{tabularx}
\usepackage{hyperref}
\usepackage{float}
\hypersetup{
    colorlinks,
    citecolor=blue,
    filecolor=black,
    linkcolor=red,
    urlcolor=blue
}
\usepackage[round]{natbib}

\input{../Comments}
\input{../Common}
\usepackage{fullpage}
\begin{document}

\title{System Verification and Validation Plan \\\progname{}} 
\author{\authname}
\date{\today}
	
\maketitle

\pagenumbering{roman}

\section{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\bf Date} & {\bf Developer} & {\bf Notes}\\
\midrule
10/30/22 & Stephen & Added General Information and Plan\\
04/03/23 & Ahmed & Final Revision\\

\bottomrule
\end{tabularx}

\newpage

\tableofcontents
\listoftables
\listoffigures



\newpage

\section{Symbols, Abbreviations and Acronyms}

\renewcommand{\arraystretch}{1.2}
\begin{tabular}{l l} 
  \toprule		
  \textbf{symbol} & \textbf{description}\\
  \midrule 
  T & Test\\
  \bottomrule
\end{tabular}\\

\wss{symbols, abbreviations or acronyms -- you can simply reference the SRS
  \citep{SRS} tables, if appropriate}

\newpage

\pagenumbering{arabic}


\section{General Information}

\subsection{Summary}

\wss{Say what software is being tested.  Give its name and a brief overview of
  its general functions.}

  Formulate consists of four subsystems, one hardware subsystem and three software subsystems, which interact to provide the user with a testing device designed to eliminate automatable processes in common testing procedures.\\

  A physical data collection device is the hardware subsystem used as the first point of contact with the measured quantity through a sensor. The sensor obtains physical quantities for the device to buffer, before sending the data to a desktop application for user verification.\\

  The user has the ability to view the data collected by the physical device after a completed test using a desktop application software subsystem. The desktop application enables the user to either accept the test results to then store a collection of data from a test to a database, or reject the test and prevent the test from being stored to a database.\\

  Accepted test data sent from the desktop application aggregates and saves verified test results to a database software subsystem. Users can query the database to obtain common statistics in test data and generate new or obscure relationships by leveraging database language capabilities.\\

  A final dashboard software subsystem then queries the database to visualize key performance indicators on the test data collected and stored in the database.\newpage





\subsection{Objectives}

\wss{State what is intended to be accomplished.  The objective will be around
  the qualities that are most important for your project.  You might have
  something like: ``build confidence in the software correctness,''
  ``demonstrate adequate usability.'' etc.  You won't list all of the qualities,
  just those that are most important.}

  The objective of the system Verification and Validation (VnV) plan for Formulate is to ensure the intended project qualities are present.\\

  Ease in user understanding is a quality Formulate will achieve to support the system's usability.  Specifically, ease in user understanding of each subsystem's function and how subsystems interface will be key qualities of the overall project.\\

  The system will also demonstrate the quality of adequate portability and physical robustness to support system maintainability, portability, and operationality.\\



\subsection{Relevant Documentation}

\wss{Reference relevant documentation.  This will definitely include your SRS
  and your other project documents (MG, MIS, etc).  You can include these even
  before they are written, since by the time the project is done, they will be
  written.}

  %Talk about how this document draws from the system requirements gathered during software requirements specification (SRS) and hazard analysis.\\

  This document references a variety of requirements generated during the Software Requirements Specification (SRS) process and the Hazard Analysis (HA) process for the Formulate system. \\


%\citet{SRS}
\newpage
\section{Plan}

\wss{Introduce this section.   You can provide a roadmap of the sections to
  come.}
  
  \subsection{Roadmap}

  The intention of testing for Formulate is to generate confidence that the project meets qualities relating to usability, maintainability, portability, operationality, and safety set out as requirements in SRS and HA documentation. Through sets of unit and system tests that will prove if the system has met the above requirements, Formulate will understand if the project has achieved the desired qualities.\\

  Specifically, requirements that are functional, non-functional, and safety-security related from the SRS and HA documents will be referenced in the Plan, System Test Description, and Unit Test Description sections of this document.\\

\subsection{Verification and Validation Team}

\wss{You, your classmates and the course instructor.  Maybe your supervisor.
  You shoud do more than list names.  You should say what each person's role is
  for the project.  A table is a good way to summarize this information.}

  \begin{table}[H]
    \centering
    \begin{tabular}{|p{3cm}|p{4cm}|p{7cm}|}
    \hline
    \multicolumn{1}{|c|}{\textbf{Name}} & \multicolumn{1}{|c|}{\textbf{Role}} & \multicolumn{1}{|c|}{\textbf{Explanation}}
    \\ \hline
    Stephen
    & Desktop Application Tester
    & VnV for software application design and integration with hardware and database
    \newline                                
    \\ \hline
  
    Ahmed                              
    & Hardware Device Tester
    & VnV for embedded program design, chassis design, and integration with desktop application
    \newline                                
    \\ \hline
  
    Muhanad                          
    & Database Application Tester
    & VnV for database design and integration with desktop application and dashboard
    \newline                                
    \\ \hline
  
    Tioluwalayomi                                
    & Dashboard Application Tester
    & VnV for dashboard application design and integration with database
    \newline                            
    \\ \hline

    Timofey                                
    & Project and Course Teaching Assistant
    & Detailed low level feedback on planned VnV tests
    \newline                            
    \\ \hline
  
    Dr. Smith                                
    & Course Instructor
    & General high level feedback on planned VnV tests 
    \newline                            
    \\ \hline
  
    \end{tabular}
  \end{table}
  \newpage

\subsection{SRS Verification Plan}

\wss{List any approaches you intend to use for SRS verification.  This may just
  be ad hoc feedback from reviewers, like your classmates, or you may have
  something more rigorous/systematic in mind..}

\wss{Remember you have an SRS checklist}

SRS verification will be composed of two approaches to verify that functional and non-functional requirements are met. The first approach is engaging in read through's of the SRS document each month. Individual member progress will be evaluated against the relevenat sections(s) of the SRS document to ensure system  development is on track to meet the requirements. The second approach is evaluating issues created by classmates on GitHub and incorporating their concerns and suggestions as seen fit.\\

Stephen and Tioluwalayomi will lead the group wide discussion for SRS verification activities on the first Tuesday of each month.\\

\subsection{Design Verification Plan}

\wss{Plans for design verification}

\wss{The review will include reviews by your classmates}

\wss{Remember you have MG and MIS checklists}

Design verification will be composed of two approaches. The first planned approach is completing read through's of each individual's high level design documentation for their respective sub-system. The design documentation covered during these read through's will likely entail mechanical, electrical, and or software schematics or diagrams outlining the architecture of the subsystem. Members will voice concerns during the read through of design decisions made by the individual responsible for the sub-system architecture. The second planned approach is evaluating issues created by classmates on GitHub and incorporating their concerns and suggestions as seen fit.\\

Ahmed will lead the group wide discussion for design verification activities on the second Tuesday of each month.\newpage

\subsection{Implementation Verification Plan}

\wss{You should at least point to the tests listed in this document and the unit
  testing plan.}

\wss{In this section you would also give any details of any plans for static verification of
  the implementation.  Potential techniques include code walkthroughs, code
  inspection, static analyzers, etc.}

  Implementation verification will be composed of techniques in both static and dynamic analysis. \\

  Content walkthrough is the primary type of static implementation verification technique the group plans on using. Three similar types of content walkthrough's are planned for use depending on the sub-system under analysis. Software implementation's will receive a code walkthrough, mechanical implementation's will receive a Computer Aided Design (CAD) spin, and electrical implementation's will receive a schematic walkthrough. During the content walkthrough, unit and system tests relevant to the implementation will be considered to critique the quality of the implementation. A meeting will be organized for each content walkthrough once the implementation has reached a notable milestone worthwile for group analysis.\\
  
  Live execution of the implementation using a proof of concept style demonstration to the group is the primary type of dynamic implementation technique the group plans on using. During the live demonstration of the implementation, system and unit tests relevant to the implementation will be considered to critique the quality of the implementation. Using the initial state and inputs of the test outlined in the system and unit test sections, the quality of implementation is passed or failed depending on if the actual output of the implementation matches the expeted output.\\

Ahmed and Muhanad will lead the group wide discussion for design verification activities on the second Tuesday of each month.\newpage

\subsection{Automated Testing and Verification Tools}

\wss{What tools are you using for automated testing.  Likely a unit testing
  framework and maybe a profiling tool, like ValGrind.  Other possible tools
  include a static analyzer, make, continuous integration tools, test coverage
  tools, etc.  Explain your plans for summarizing code coverage metrics.
  Linters are another important class of tools.  For the programming language
  you select, you should look at the available linters.  There may also be tools
  that verify that coding standards have been respected, like flake9 for
  Python.}

  Tools will not be used to automate testing, profile, or code coverage for software flashed on embedded hardware because of the available tools incur high additional overhead to testing effort and times. The group plans on completing extensive unit testing for embedded software to compensate for the absence of automated testing and coverage tools.\\

  The desktop application will likely use Visual Studio's memory usage tool to profile the program during execution.\\
%Stephen updated this section, Sunday afternoon
  %PyLint and SQLFluff will be used as the static code analysis tools to support uniformity in the desktop application and database programs respectively.\\

  Code coverage will be completed manually for the desktop, database, and the dashboard programs. This decision will be feasible as the expected size of software for the applications listed above is relatively small. As a result, it is reasonable for to manually check the amount of code coverage achieved through tests.\\

\wss{The details of this section will likely evolve as you get closer to the
  implementation.}

\subsection{Software Validation Plan}

\wss{If there is any external data that can be used for validation, you should
  point to it here.  If there are no plans for validation, you should state that
  here.}

  There are no current plans to use external data for validation.\newpage

\section{System Test Description}
	
\subsection{Tests for Functional Requirements}

\wss{Subsets of the tests may be in related, so this section is divided into
  different areas.  If there are no identifiable subsets for the tests, this
  level of document structure can be removed.}

\wss{Include a blurb here to explain why the subsections below
  cover the requirements.  References to the SRS would be good.}

\subsubsection{Hardware Device}

\wss{It would be nice to have a blurb here to explain why the subsections below
  cover the requirements.  References to the SRS would be good.  If a section
  covers tests for input constraints, you should reference the data constraints
  table in the SRS.}
		
\paragraph{Sensor Validation}

\begin{enumerate}

\item{\bf{ST-SV 1}}

\underline{Type:} Manual
					
\underline{Initial State:} Device is on, measuring and sending values to the application, and connection to database has been verified
					
\underline{Input:} The device is placed in temperature controlled box at 25$^{\circ}$C
%Stephen updated this section, Sunday afternoon
					
\underline{Output:} The temperature sensor on the device should consistently read 25$^{\circ}$C within a 5\% error for ten successive readings 

%Test Case Derivation: \wss{Justify the expected value given in the Output field}
					
\underline{How test will be performed:} The device will be placed in a styrofoam insulated box and a hair dryer will be used to heat the box to 25$^{\circ}$C. Using a digital thermometer we will compare the results of our device to the digital thermometer\\

		
\item{\bf{ST-SV 2}}

\underline{Type:} Manual
					
\underline{Initial State:} Device is on, measuring and sending values to the application, and connection to database has been verified
					
\underline{Input:} The device will be placed in a humidity controlled box which will be 40\% humidity
%Stephen updated this section, Sunday afternoon
					
\underline{Output:} The humidity sensor on the device should consistently read 40\% humidity within a 5\% error for 10 successive readings

\underline{How test will be performed:} The device will be placed in a styrofoam insulated box and a hair dryer will be used to heat the box to 50$^{\circ}$C. Using a digital humidity monitor we will compare the results of our device to the digital sensor

\item{\bf{ST-SV 3}}

\underline{Type:} Manual
					
\underline{Initial State:} Device is on, measuring and sending values to the application, and connection to database has been verified
%Stephen updated this section, Sunday afternoon
\underline{Input:} The device will be placed on a constantly vibrating platform at 1 Hertz for 10 seconds.
					
\underline{Output:} The accelerometer sensor should consistently read a vibration of 1 Hz within a 5\% error for 10 seconds

\underline{How test will be performed:} The device will be placed on a constantly vibrating platform which is set to a known vibration. We will start a test on our device and compare the output of our accelerometer with the known vibration

\end{enumerate}

\paragraph{Device Telemetry}	
\begin{enumerate}

  \item{\bf{ST-DT 1}}
  
  \underline{Type:} Manual
            
  \underline{Initial State:} Device is on and is connected to a PC via cable or via Wi-Fi
            
  \underline{Input:} The start button is pressed
            
  \underline{Output:} All readings from all sensors should be sent to the PC for 30 consecutive readings within 1 second of pressing the start button
  
  %Test Case Derivation: \wss{Justify the expected value given in the Output field}
            
  \underline{How test will be performed:} While the device is connected to the PC the start button will be pressed to check if telemetry data is being sent to the PC. The emphasis is on the ability of data transmission and not correctness\\

  \item{\bf{ST-DT 2}}
  
  \underline{Type:} Manual
            
  \underline{Initial State:} Device is on and is connected to a PC via cable or via Wi-Fi
            
  \underline{Input:} The start button is pressed 10 times consecutively
            
  \underline{Output:} The device should continue to send data to the PC regardless of how many times the start button is pressed
  
  %Test Case Derivation: \wss{Justify the expected value given in the Output field}
            
  \underline{ How test will be performed:} While the device is connected to the PC the start button will be pressed and then after a few seconds pressed again 10 more times to check if telemetry data transmission to the PC cannot be broken by pressing the start button\\

  \item{\bf{ST-DT 3}}
  
  \underline{Type:} Manual
            
  \underline{Initial State:} Device is on and is connected to a PC via cable or via Wi-Fi
            
  \underline{Input:} The stop button is pressed
            
  \underline{Output:} All sensor readings should stop being sent to the PC within 1 second of pressing the stop button
  
  %Test Case Derivation: \wss{Justify the expected value given in the Output field}
            
  \underline{How test will be performed:} While the device is connected to the PC the stop button will be pressed to check if telemetry data is stopped\\

  \item{\bf{ST-DT 4}}
  
  \underline{Type:} Manual
            
  \underline{Initial State:} Device is on and is connected to a PC via cable or via Wi-Fi
            
  \underline{Input:} The stop button is pressed 10 times
            
  \underline{Output:} The device should not send data to the PC regardless of how many times the stop button is pressed
  
  %Test Case Derivation: \wss{Justify the expected value given in the Output field}
            
  \underline{How test will be performed:} While the device is connected to the PC the stop button will be pressed 10 times in an interval of 2 seconds to check if telemetry data is has stopped\\

  \end{enumerate}

  \paragraph{Device Hardware}	
  \begin{enumerate}
  
    \item{\bf{ST-DH 1}}
    
    \underline{Type:} Manual
              
    \underline{Initial State:} Device is on and is connected to a PC, no sensors are attached
              
    \underline{Input:} A sensor is connected using the snap on connector and start is pressed
              
    \underline{Output:} The device should start sending data to the PC within 1 second of pressing the start button and should be firmly attached to the device at a vibration of 1 Hertz.
              
    \underline{How test will be performed:} While the device is connected to the PC a sensor is connected to the modular port on the device and the start button is pressed, the sensor will be shaken at 1 Hertz and it should still continue to send data\\
  
    \item{\bf{ST-DH 2}}
    %Stephen updated this section, Sunday afternoon
    \underline{Type:} Manual
              
    \underline{Initial State:} Device is on but the battery has less than 5 minutes of charge
              
    \underline{Input:} User swaps the battery
              
    \underline{Output} The battery should provide a full 2 hours of charge in testing time
    
    %Test Case Derivation: \wss{Justify the expected value given in the Output field}
              
    \underline{How test will be performed:} We will continue to use the device until the battery is completely drained, once its low we will start to charge it and check if the battery increases\\

    \item{\bf{ST-DH 3}}
    
    \underline{Type:} Manual
              
    \underline{Initial State:} Device is fully mounted on a test platform
              
    \underline{Input:} User will apply 49N of force on every side of the device
              
    \underline{Output:} The fastened device should not show signs of deformation or changes in position

    \underline{Rationale:} This will test the rigidity and durability of our mounting mechanism and ensure that our device can withstand the forces it will face while mounted on a Formula E vehicle.
    
    %Test Case Derivation: \wss{Justify the expected value given in the Output field}
              
    \underline{How test will be performed:} Once the device is mounted we will place 5kg on top of different sides of the device to check if the mount can withstand it \\

    \item{\bf{ST-DH 4}}
    
    \underline{Type:} Manual
              
    \underline{Initial State:} Device is not mounted on anything
              
    \underline{Input:} User will begin to mount the device on the Formula SAE car
              
    \underline{Output:} The device should be fully installed under 5 minutes
    
    %Test Case Derivation: \wss{Justify the expected value given in the Output field}
              
    \underline{How test will be performed:} While someone is mounting the device another person is timing them \\

    %Stephen updated this section, Sunday afternoon
    %\item{\bf{ST-DH 5}}
    
   % Type: Manual
              
   % Initial State: Device is on and is connected to a PC via cable or via Wi-Fi. The operating conditions need to be set
              
    %Input: User will place the device in an environment at 30$^{\circ}$C
              
   % Output: The device should alert the user that operating conditions are exceeded via the screen and speaker
    
    %Test Case Derivation: \wss{Justify the expected value given in the Output field}
              
    %How test will be performed: The operating condition of the device will be set to 25$^{\circ}$C using the desktop application and the device will then be placed in a 30$^{\circ}$C environment\\
  
    \end{enumerate}


\subsubsection{Desktop Application}

\begin{enumerate}
  
  \item{\bf{ST-DA 1}}
  
  \underline{Type:} Manual
            
  \underline{Initial State:} Device is on and is connected to a PC, the desktop application is open and connected to the device
            
  \underline{Input:} User selects the retrieve test case
            
  \underline{Output:} A table with all the raw test data should populate the screen
  
  \underline{Rationale:} This tests if the desktop application can read the last test performed from the local storage incase connectivity was lost \wss{Justify the expected value given in the Output field}
            
  \underline{How test will be performed:} After a test is completed on the device, it will be connected to the PC and the user should be able to view the most recent test after clicking retrieve\\

  %\item{\bf{ST-DA 2}}
  
  %Type: Manual
            
  %Initial State: Device is on and is connected to a PC, the desktop application is open and test data is open
            
  %Input: User selects rows and columns to delete and hits the delete key
            
  %Output: The table with the test data should update to reflect the newly deleted rows
  
  %Test Case Derivation: \wss{Justify the expected value given in the Output field}
            
  %How test will be performed: A test will be conducted but the start button will be pressed early, the initial 20 seconds of the test does not provide useful data and the user will select and delete those rows\\

  \item{\bf{ST-DA 3}}
  
  \underline{Type:} Manual
            
  \underline{Initial State:} Device is on and is connected to a PC, the desktop application is open and test data is open
            
  \underline{Input:} User hits the submit to database button
            
  \underline{Output:} The test data in the table should be sent to the database
  
  \underline{Rationale:} This will test if the desktop application can connect with the database and send data
  %Test Case Derivation: \wss{Justify the expected value given in the Output field}
            
  \underline{How test will be performed:} After a test is conducted and the data will be viewed on the desktop app, the user will preview the data and click submit to database \\

  \item{\bf{ST-DA 4}}
  
  \underline{Type:} Manual
            
  \underline{Initial State:} Device is on and is connected to a PC, the desktop application is open but no tests are done
            
  \underline{Input:} User hits the submit to database button
            
  \underline{Output:} The application should alert the user that no data was recorded and not send anything to the database
  
  %Test Case Derivation: \wss{Justify the expected value given in the Output field}
            
  \underline{How test will be performed:} No tests will be performed and an empty table will be shown. Submit to database will be clicked \\

  \item{\bf{ST-DA 5}}
  
  \underline{Type:} Manual
            
  \underline{Initial State:} Device is on and is connected to a PC, the desktop application is open
            
  \underline{Input:} User clicks the start test button on the application
            
  \underline{Output:} The application should start to receive live data from the device and display it on the table
  
  %Test Case Derivation: \wss{Justify the expected value given in the Output field}
  \underline{Rationale:} This test verifies that our desktop application can read live data as the sensors are outputting them
            
  \underline{How test will be performed:} The hardware device will be plugged into the PC and once we hit the start button on the application all the sensors will display their output\\
  

\end{enumerate}

\subsubsection{Data Analytics Website}
\begin{enumerate}
  
  \item{\bf{ST-DAW 1}}
  
  \underline{Type:} Manual
            
  \underline{Initial State:} The database contains test data and is connected to the analytics platform
            
  \underline{Input:} User logs into the analytics platform and selects a test
            
  \underline{Output:} The test data is displayed showing the results over time for that particular test
  
  %Test Case Derivation: \wss{Justify the expected value given in the Output field}
            
  \underline{How test will be performed:} We will populate the database with different tests and the user once logged in will select a specific test to view\\

  \item{\bf{ST-DAW 2}}
  
  \underline{Type:} Manual
            
  \underline{Initial State:} The database contains test data and is connected to the analytics platform
            
  \underline{Input:} Unauthorized user attempts to login
            
  \underline{Output:} The website alerts the user they are not authorized to view the dashboard
  
  %Test Case Derivation: \wss{Justify the expected value given in the Output field}
            
  \underline{How test will be performed:} One team member will not have privileges to view the dashboard and will attempt to login\\

\end{enumerate}

\subsubsection{Database}

\begin{enumerate}
  
  \item{\bf{ST-D 1}}
  
  \underline{Type:} Manual
            
  \underline{Initial State:} Database is active
            
  \underline{Input:} User submits data multiple times within 5 seconds
            
  \underline{Output:} Database stops accepting new data and alerts user

  \underline{Rationale:} This test will check if it is possible to spam the database with data, it keeps the database safe from unintended purposes
            
  \underline{How test will be performed:} After a test is completed on the device, it will be previewed using the desktop app and the submit to database button will be pressed repeatedly\\
\end{enumerate}

\subsection{Tests for Nonfunctional Requirements}
System tests for nonfunctional requirements are broken down into performance and usability subsets. Performance tests are used to measure speed, modularity, responsiveness, and stability of
the device, application and database. Usability tests are more user-related in the sense that they are validated through users operating the device and taking measurements. These tests allow the Formulate system to be evaluated 
through user's perspective.

\wss{The nonfunctional requirements for accuracy will likely just reference the
  appropriate functional tests from above.  The test cases should mention
  reporting the relative error for these tests.}

\wss{Tests related to usability could include conducting a usability test and
  survey.}

\subsubsection{Performance}
		
\begin{enumerate}

\item{\bf{ST-P 1}}

Type: Dynamic, Manual
					
Initial State: Device is on and mounted, has connected to the application and is waiting to start measuring.
					
Input/Condition: Measurements begin
					
Output/Result: Device is operational and stays physically intact in conditions at 20\% greater than threshold values and in all types of weather.
					
How test will be performed: The device will be tested outdoors under various weather conditions including rain, wind, etc.
The device will also be tested in temperature and vibration conditions that are above threshold values. This will be performed by placing the device in a hot environment
and vigorously shaking it.
					
\item{\bf{ST-P 2}}

Type: Dynamic, Manual
					
Initial State: Device is on and mounted, has connected to the application and is waiting to start measuring.
					
Input: Measurements begin
					
Output/Result: Data latency should be less than 10 seconds to simulate viewing live data.
					
How test will be performed: The amount of time for data to be viewable on the application will be inspected to be less than 10 seconds.
The application UI will also be inspected to ensure that data is smooth and not lagging while measurements are being performed.

\item{\bf{ST-P 3}}

Type: Dynamic, Manual
					
Initial State: Device measuring and sending values to the application, and connection to the database has been verified
					
Input: One or two of either the device, application, or database are disconnected or turned off
					
Output: The other two components are still functional even though communication between them is broken.
					
How test will be performed: While device, application, and database are fully functional and communicating successfully, different combinations of either one or two components
will be turned off. The other component(s) will be inspected to ensure that they are operational and indicating that the other component(s) are disconnected.

\end{enumerate}
\newpage
\subsubsection{Usability}

\begin{enumerate}
%Stephen updated this section, Sunday afternoon
\item{\bf{ST-U 1-A}}

Type: Dynamic, Manual
          
Initial State: Device is turned off and nothing is connected, only the application is loaded on to the computer and the correct Arduino code to the test setup is flashed onto the micro-controller
          
Input/Condition: Users will be asked to setup device and start taking measurements, and the rate setup process using a survey
          
Output/Result: Time for setup and data to appear on the application should be less than 5 minutes and an average score of 3 should be achieved on each user's survey.
          
How test will be performed: A test group will be educated on the setup and connection of the device, then they will attempt to do that process. 
Each person will be timed and compared to the 5 minute threshold. In addition, they will be given a survey to rate the difficulty of the setup process on a scale from 
1 to 5 on the following categories: overall setup, sensor mount, device mount, start up procedure, and measuring procedure (refer to SQ1).  
%Stephen updated this section, Sunday afternoon
\item{\bf{ST-U 1-B}}

Type: Dynamic, Manual
          
Initial State: Device is turned off and nothing is connected, only the application is loaded on to the computer and the Arduino code must be adjusted to the test setup is flashed onto the micro-controller
          
Input/Condition: Users will be asked to setup device and start taking measurements, and the rate setup process using a survey
          
Output/Result: Time for setup and data to appear on the application should be less than 5 minutes and an average score of 3 should be achieved on each user's survey.
          
How test will be performed: A test group will be educated on the setup and connection of the device, then they will attempt to do that process. 
Each person will be timed and compared to the 5 minute threshold. In addition, they will be given a survey to rate the difficulty of the setup process on a scale from 
1 to 5 on the following categories: overall setup, sensor mount, device mount, start up procedure, and measuring procedure (refer to SQ1).  
%Stephen updated this section, Sunday afternoon
\item{\bf{ST-U 2-A}}

Type: Dynamic, Manual
					
Initial State: Device is given to McMaster's Formula Electric team to use with a wired connection to the laptop
					
Input/Condition: Using a survey, Formula Electric members will compare their current testing process to the Formulate process
					
Output/Result: All users need to select Formulate in at least 3 of the 4 categories
					
How test will be performed: Formula E members will select which process is preferred in the following categories: speed, data collection, ease of use, and portability (refer to SQ2).
%Stephen updated this section, Sunday afternoon
\item{\bf{ST-U 2-B}}

Type: Dynamic, Manual
					
Initial State: Device is given to McMaster's Formula Electric team to use with a wireless connection to the laptop
					
Input/Condition: Using a survey, Formula Electric members will compare their current testing process to the Formulate process
					
Output/Result: All users need to select Formulate in at least 3 of the 4 categories
					
How test will be performed: Formula E members will select which process is preferred in the following categories: speed, data collection, ease of use, and portability (refer to SQ2).
%Stephen updated this section, Sunday afternoon
\item{\bf{ST-U 3-A}}

Type: Dynamic, Manual
					
Initial State: Device is set up and waiting to start measuring via a wired connection, application is loaded onto the computer
					
Input/Condition: Users are asked to log into the application and use the UI to observe data. The wired connection is broken by removing the physical connection. Users are asked through a survey how easy the recovery method for test data collected onto the local memory was and submitting the data to the database
					
Output/Result: An average score of 3 should be achieved on each user's survey
					
How test will be performed: A test group will be asked to use the application UI and rate it on the following categories on a scale from 1 to 5: login process, responsiveness, accessibility, and sending results to the database (refer to SQ3).
%Stephen updated this section, Sunday afternoon
\item{\bf{ST-U 3-B}}

Type: Dynamic, Manual
					
Initial State: Device is set up and waiting to start measuring, application is loaded onto the computer, the user is logged in
					
Input/Condition: Users are asked to use the UI to observe data and send results to the database, and rate the UI using a survey when the connection between the UI and the database was broken
					
Output/Result: An average score of 3 should be achieved on each user's survey
					
How test will be performed: A test group will be asked to use the application UI and rate it on the following categories on a scale from 1 to 5: login process, responsiveness, accessibility, and sending results to the database (refer to SQ3).
%Stephen updated this section, Sunday afternoon
%% NOTE: Do we need this section? I commented this out for now (S.O)
%\item{\bf{ST-U 4}}

%Type: Dynamic, Manual
					
%Initial State: Device is set up and waiting to start measuring, application is loaded onto the computer
					
%Input/Condition: Users will begin testing a variety of test on the equipment.
					
%utput/Result: Users will either be allowed to continue test or not depending of the compatability of the test to our device.
					
%How test will be performed: Users will begin testing doing different tests with different equipment and based on the the compatability of the equipment to the test it will either allow you to continue or stop you from running the test to help avoid damaging equipment.

\end{enumerate}

\subsubsection{Security}

\begin{enumerate}

  \item{\bf{ST-S 1}}

  Type: Dynamic, Manual
            
  Initial State: The device will have measurements stored in the database after a test is completed.
            
  Input: User will input multiple usernames and passwords to try open the database and see the data that has been stored.
            
  Output: Depending on the username and password inputed the user will either be able to see the data or be prompted with an error message.
            
  How test will be performed: After the user has conducted a test and wants to view their data they will be asked for a username and password to verify that they are the intended user of the device. Depending on the username and password they will either be allowed to view the data or be blocked off.

  
  \item{\bf{ST-S 2}}
  
  Type: Dynamic, Manual
            
  Initial State:The device will have measurements stored in the database after a test is completed.
            
  Input: Multiple fake data points will be attempted to be added by an unauthorized user.
            
  Output: The data points taken from the device will not be affected and will remain the same regardless of attempts to alter it.
            
  How test will be performed: A user will attempt to change and compromise the data points that are being stored in the database. A security feature will stop this from happening unless the user is authorized to do so.
  

  
\end{enumerate}


\subsection{Traceability Between Test Cases and Requirements}
\begin{tabular}{| p{0.45\textwidth} | p{0.45\textwidth}|}
  \hline
  \rowcolor[gray]{0.9}
  Requirement & Test \\
  \hline
  FR 1 & ST-SV 1, ST-SV 2, ST-SV 3 \\
  \hline
  FR 2 & ST-DT 1, ST-DT 2, ST-DT 3, ST-DT 4 \\
  \hline
  FR 3 & ST-DT 1, ST-DT 2 \\
  \hline
  FR 4 & ST-DT 3, ST-DT 4 \\
  \hline
  FR 5 & ST-SV 1, ST-SV 2, ST-SV 3 \\
  \hline
  FR 6 & ST-DA 1 \\
  \hline
  FR 7 & ST-DA 3 ST-DA 4 \\
  \hline
  FR 8 & ST-DAW 1 \\
  \hline
  FR 9 & ST-DH 3 \\
  \hline
  FR 10 & ST-DH 4 \\
  \hline
  FR 11 & ST-DH 2 \\
  \hline
  FR 12 & ST-DT 1, ST-DT 2 \\
  \hline
  FR 14 & ST-DH 1 \\
  \hline
  FR 15 & ST-DA 5\\
  \hline
  FR 16 & ST-DH 5 \\
  \hline
  FR 17 & ST-DA 1 \\
  \hline
  FR 18 & ST-DA 2 \\
  \hline
  FR 19 & ST-DAW 2 \\
  \hline
  FR 20 & ST-DAW 1 \\
  \hline
  FR 21 & ST-DAW 1 \\
  \hline
  FR 22 & ST-D 1 \\
  \hline
  FR 23 & ST-DH 5 \\
  \hline
  NFR 1 & ST-U 1 ST-U 2 ST-U 3 \\
  \hline
  NFR 2 & ST-U 1 ST-U 2 ST-U 3 \\
  \hline
  NFR 3 & ST-P 2 \\
  \hline
  NFR 4 & ST-P 1 ST-P 3 \\
  \hline
  NFR 5 & ST-U 4 \\
  \hline
  NFR 6 & ST-P 1 \\
  \hline
  NFR 7 & ST-P 3 \\
  \hline
  NFR 8 & ST-U 2 \\
  \hline
  NFR 9 & ST-S 1 ST-S 2 \\
  \hline
\end{tabular}
\wss{Provide a table that shows which test cases are supporting which
  requirements.}

  \newpage




\wss{Provide evidence that all of the modules have been considered.}
				

\section{References}
Oh, S., Nazir, A., Sada, M., amp; Babayeju, T. (n.d.). (rep.). Software Requirements Specification MECHTRON 4TB6: Formulate. \\
\noindent \\
Oh, S., Nazir, A., Sada, M., amp; Babayeju, T. (n.d.). (rep.). Hazard Analysis MECHTRON 4TB6. \\

\newpage
\section{Appendix}


\subsection{Usability Survey Questions}

\begin{enumerate}
  \item[\bf{SQ1}]{How difficult was the setup process? Rate the difficulty of the following components of the setup process on a scale from 1 to 5: overall setup, sensor mount, device mount, start up procedure, and measuring procedure. }
  
  \item[\bf{SQ2}]{Which testing process do you prefer based on the following categories: speed, data collection, ease of use, and portability. }
  
  \item[\bf{SQ3}]{How did you enjoy your experience using Formulate's application UI? Rate the UI on the following categories from 1 to 5: login process, responsiveness, accessibility, and sending results to the database.}

\end{enumerate}


\subsection{Reflection}
\subsubsection{Knowledge Required}
  \begin{enumerate}
    \item In order to ensure the success of our project, it is essential that our team enhances our understanding of how sensors operate, as we work to complete our verification and validation plan. It is imperative that we accurately capture and interpret data from the sensors, which entails mitigating any potential interference, optimizing calibration, and implementing the sensors effectively. Only by mastering these critical aspects of sensor technology can we ensure that our device functions properly and delivers optimal performance.
  
  \end{enumerate}

\subsubsection{Approach}
  \begin{enumerate}
    \item Our team aims to elevate our sensor expertise through a twofold approach. Firstly, we plan to conduct extensive research on the workings of digital and analog sensors, utilizing a range of resources such as scholarly papers and informative YouTube videos. This will enable us to establish a firm theoretical foundation of sensor fundamentals, allowing us to comprehend and apply sensor concepts more effectively. Secondly, we will embark on a practical journey by conducting experiments on our current sensors to explore the impact of various environmental factors on their performance. By subjecting these sensors to different conditions, we can identify the optimal configuration to obtain the most accurate readings. This hands-on approach will supplement our theoretical knowledge and provide valuable insights into the real-world application of sensor technology. From our team Ahmed will be pursing this because of his previous coop background utilizing different sensors and his general interest in the area.
  
  \end{enumerate}


\wss{This is a section that would be appropriate for some projects.}

\end{document}